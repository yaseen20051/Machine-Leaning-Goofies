{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3544a8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_150201/534103545.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataset[column].fillna(dataset[column].mean(),inplace = True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler,MinMaxScaler\n",
    "from collections import Counter\n",
    "\n",
    "def check_duplicates(dataset):\n",
    "        return dataset.drop_duplicates()\n",
    "def check_missing_values(dataset):\n",
    "        for column in dataset.columns :\n",
    "                if(dataset[column].isnull().sum() > 0):\n",
    "                        dataset[column].fillna(dataset[column].mean(),inplace = True)\n",
    "        return dataset\n",
    "\n",
    "def feature_transformatiom(dataset):\n",
    "      # plot Box \n",
    "        # X = dataset.drop('class', axis=1).copy(deep=True)\n",
    "        # first_quartile = X.quantile(0.25)\n",
    "        # median = X.quantile(0.5)\n",
    "        # third_quartile = X.quantile(0.75)\n",
    "        # IQR = third_quartile - first_quartile\n",
    "        # X = (X- median)/IQR\n",
    "        # print(X)\n",
    "      # log transform\n",
    "                # transform = FunctionTransformer(np.log1p)\n",
    "                # for column in dataset.drop('class',axis = 1).columns :\n",
    "                #     dataset[column] = transform.fit_transform(dataset[[column]])\n",
    "      # yeo_johnson transform\n",
    "      \n",
    "        # pt = PowerTransformer(method='yeo-johnson')\n",
    "        # for column in dataset.drop('class',axis = 1).columns :\n",
    "        #                 dataset_transformed = pt.fit_transform(dataset[[column]])\n",
    "        #                 dataset[column] = pd.DataFrame(dataset_transformed, columns=[column])\n",
    "\n",
    "      # Robust transform (value - median) / IQR\n",
    "        for column in dataset.drop('class',axis = 1).columns :\n",
    "                        \n",
    "                        scaler  = RobustScaler()\n",
    "                        dataset[column] = scaler.fit_transform(dataset[[column]])   ## learn and practise at the same time \n",
    "        # print(dataset)\n",
    "        return dataset\n",
    "def data_preprocessing(dataset_file):\n",
    "        dataset = pd.read_csv(dataset_file)\n",
    "        dataset.drop('Unnamed: 0',axis = 1,inplace = True)\n",
    "                \n",
    "\n",
    "        ## checking duplicates\n",
    "        dataset = check_duplicates(dataset)\n",
    "\n",
    "\n",
    "        ## checking missing values \n",
    "        dataset = check_missing_values(dataset)\n",
    "\n",
    "\n",
    "        # Correlations\n",
    "        # corr_features = dataset.drop(\"class\", axis=1).corr()\n",
    "        # print(corr_features)\n",
    "\n",
    "        ## Feature tranformation \n",
    "        dataset = feature_transformatiom(dataset)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "class knn_classifier():\n",
    "    def __init__(self,n_neighbor):\n",
    "            self.n_neighbour = n_neighbor\n",
    "\n",
    "    def model_learn(self,X,y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def data_split(self,dataset):\n",
    "        train_data_full = dataset.sample(frac=0.8, random_state=42)\n",
    "        test_data = dataset.drop(train_data_full.index)\n",
    "        vaildation_data = train_data_full.sample(frac=0.2, random_state=42)\n",
    "        train_data = train_data_full.drop(vaildation_data.index)\n",
    "\n",
    "        return train_data,vaildation_data,train_data_full, test_data\n",
    "    \n",
    "    def predict(self,X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            predictions.append(self._predict_single(x))\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def euclidean_distance(self,a,b):\n",
    "          return np.sqrt(np.sum((a - b)**2))\n",
    "    \n",
    "    def _predict_single(self,x):\n",
    "        distances = []\n",
    "        for x_train in self.X_train:\n",
    "            distances.append(self.euclidean_distance(x, x_train))\n",
    "        distances = np.array(distances)\n",
    "        k_indices = np.argsort(distances)[:self.n_neighbour]\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "        most_common = Counter(k_nearest_labels).most_common(1)\n",
    "        return most_common[0][0]\n",
    "    \n",
    "    def accuracy(self,y_true,y_pred):\n",
    "        correct = np.sum(y_true == y_pred)\n",
    "        return correct / len(y_true)      \n",
    "\n",
    "    def knn_classifier(self,dataset):\n",
    "\n",
    "        train_data,vaildation_data,train_data_full,test_data = self.data_split(dataset)\n",
    "        x_train = train_data.drop('class',axis = 1).values\n",
    "        y_train = train_data['class'].values\n",
    "        x_vaildation = vaildation_data.drop('class',axis = 1).values\n",
    "        y_vaildation = vaildation_data['class'].values\n",
    "        x_train_full = train_data_full.drop('class',axis = 1).values\n",
    "        y_train_full = train_data_full['class'].values\n",
    "        X_test = test_data.drop('class',axis = 1).values\n",
    "        y_test = test_data['class'].values\n",
    "\n",
    "            \n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(x_train)\n",
    "        x_train = scaler.transform(x_train)\n",
    "        x_vaildation = scaler.transform(x_vaildation)\n",
    "        x_train_full = scaler.transform(x_train_full)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "    \n",
    "        k_values = range(1, 11)\n",
    "        training_accuracy = []\n",
    "        validation_accuracy = []\n",
    "\n",
    "        for k in k_values:\n",
    "            self.n_neighbour = k\n",
    "            self.model_learn(x_train, y_train)\n",
    "            train_pred = self.predict(x_train)\n",
    "            val_pred = self.predict(x_vaildation)\n",
    "            training_accuracy.append(self.accuracy(y_train, train_pred))\n",
    "            validation_accuracy.append(self.accuracy(y_vaildation, val_pred))\n",
    "\n",
    "        training_accuracy = np.array(training_accuracy)\n",
    "        validation_accuracy = np.array(validation_accuracy)\n",
    "\n",
    "        best_k_train = np.argmax(training_accuracy) + 1\n",
    "        best_acc_train = training_accuracy[best_k_train - 1]\n",
    "        best_k_val = np.argmax(validation_accuracy) + 1\n",
    "        best_acc_val = validation_accuracy[best_k_val - 1]\n",
    "\n",
    "        print(f\"Best training accuracy: {best_acc_train:.4f} at k={best_k_train}\")\n",
    "        print(f\"Best validation accuracy: {best_acc_val:.4f} at k={best_k_val}\")\n",
    "\n",
    "        plt.figure(figsize=(8,5))\n",
    "        plt.plot(k_values, training_accuracy, label=\"Training Accuracy\", marker='o')\n",
    "        plt.plot(k_values, validation_accuracy, label=\"Validation Accuracy\", marker='o')\n",
    "        plt.scatter(best_k_val, best_acc_val, color='red', s=100, label=f\"Best k={best_k_val}\")\n",
    "        plt.xlabel(\"Number of Neighbors (k)\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.title(\"KNN Accuracy vs Number of Neighbors\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        self.n_neighbour = best_k_val\n",
    "        self.model_learn(x_train_full, y_train_full)\n",
    "        test_pred = self.predict(X_test)\n",
    "        test_accuracy = self.accuracy(y_test, test_pred)\n",
    "        print(f\"Test accuracy: {test_accuracy:.4f} at k={best_k_val}\")\n",
    "\n",
    "        plt.figure(figsize=(7,5))\n",
    "        plt.scatter(best_k_val, test_accuracy, color='red', s=100, label=f\"Test Accuracy={test_accuracy:.2f}\")\n",
    "        plt.xlabel(\"Best k\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.title(\"Test KNN Accuracy\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "                \n",
    "\n",
    "            \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "dataset = data_preprocessing('telescope_data.csv')\n",
    "classifier = knn_classifier(n_neighbor=3)\n",
    "classifier.knn_classifier(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0328c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255aea50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
